{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import splitfolders\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from pipeline_torch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=yaml.load(open('config.yml', 'r'), Loader=yaml.FullLoader)\n",
    "seed = config['model_config']['initial_seed']\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1160 files [00:11, 99.68 files/s] \n",
      "Copying files: 464 files [00:04, 104.04 files/s]\n"
     ]
    }
   ],
   "source": [
    "# define training and test data directories\n",
    "data_dir  = r'..\\DL_input_data\\ScenarioAlpha\\Sensor1'\n",
    "train_valid_dir = os.path.join(data_dir) \n",
    "#test_dir  = os.path.join(data_dir, 'test')\n",
    "\n",
    "splitfolders.ratio(input=train_valid_dir, output='split_data', ratio=(0.6, 0.4))\n",
    "train_dir='split_data/train'\n",
    "valid_dir='split_data/val'\n",
    "\n",
    "splitfolders.ratio(input='split_data/val', output='Valid_Test', ratio=(0.5, 0.5))\n",
    "valid_dir='Valid_Test/train'\n",
    "test_dir='Valid_Test/val'\n",
    "\n",
    "# Selecting mean and std values according to ImageNet dataset\n",
    "mean = torch.tensor( [0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and transform data using ImageFolder\n",
    "data_transforms = {\n",
    "    'train':  transforms.Compose([\n",
    "                                transforms.Resize([224,224]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean,std)\n",
    "                                ]),\n",
    "    'validation':  transforms.Compose([\n",
    "                                transforms.Resize([224,224]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean,std)\n",
    "                                ]),\n",
    "    'test':  transforms.Compose([\n",
    "                                transforms.Resize([224,224]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean,std)\n",
    "                                ])\n",
    "}\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=data_transforms[\"train\"])\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=data_transforms[\"validation\"])\n",
    "test_data  = datasets.ImageFolder(test_dir, transform=data_transforms[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model and freezing the layers\n",
    "model_transfer = models.resnet50(pretrained=True)\n",
    "layers=list(model_transfer._modules.keys())\n",
    "\n",
    "layers_frozen=layers[0:8]\n",
    "\n",
    "for layer in layers_frozen:\n",
    "    for param in model_transfer._modules[layer].parameters():\n",
    "        param.requires_grad=False\n",
    "        \n",
    "# modify last layer to match it our classes\n",
    "n_inputs = model_transfer.fc.in_features\n",
    "last_layer = nn.Linear(n_inputs, len(train_data.classes))\n",
    "model_transfer.fc = last_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PipelineTorch(model_transfer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Learning Rate: 0.000909\n",
      "Duration of training at epoch 1 is : 0:00:40.299760 seconds.\n",
      "Epoch: 1 \tTraining Loss: 1.072934 \tValidation Loss: 0.699033\n",
      "seed has been changed. The new torch seed is 10\n",
      "Validation loss has descreased (inf-->0.699033). Saving model...\n",
      "Epoch [2/5], Learning Rate: 0.000800\n",
      "Duration of training at epoch 2 is : 0:00:41.852769 seconds.\n",
      "Epoch: 2 \tTraining Loss: 0.635094 \tValidation Loss: 0.545275\n",
      "Validation loss has descreased (0.699033-->0.545275). Saving model...\n",
      "Epoch [3/5], Learning Rate: 0.000661\n",
      "Duration of training at epoch 3 is : 0:00:41.826077 seconds.\n",
      "Epoch: 3 \tTraining Loss: 0.432944 \tValidation Loss: 0.357440\n",
      "Validation loss has descreased (0.545275-->0.357440). Saving model...\n",
      "Epoch [4/5], Learning Rate: 0.000507\n",
      "Duration of training at epoch 4 is : 0:00:42.096077 seconds.\n",
      "Epoch: 4 \tTraining Loss: 0.340277 \tValidation Loss: 0.310940\n",
      "Validation loss has descreased (0.357440-->0.310940). Saving model...\n",
      "Epoch [5/5], Learning Rate: 0.000352\n",
      "Duration of training at epoch 5 is : 0:00:42.951628 seconds.\n",
      "Epoch: 5 \tTraining Loss: 0.281513 \tValidation Loss: 0.285366\n",
      "Validation loss has descreased (0.310940-->0.285366). Saving model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pipeline_torch.PipelineTorch at 0x1cf918d2d10>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.train(train_data, valid_data, config['model_config']['version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'models\\model_v1.pth'\n",
      "=> loaded checkpoint 'models\\model_v1.pth' (epoch 5)\n"
     ]
    }
   ],
   "source": [
    "pipeline.load_checkpoint(config['model_config']['version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.265883\n",
      "\n",
      "\n",
      "Test Accuracy: 97% (226/232)\n"
     ]
    }
   ],
   "source": [
    "losses, average_loss, predictions, real_labels = pipeline.predict(test_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        58\n",
      "           1       1.00      0.97      0.98        58\n",
      "           2       1.00      0.98      0.99        58\n",
      "           3       0.93      0.97      0.95        58\n",
      "\n",
      "    accuracy                           0.97       232\n",
      "   macro avg       0.97      0.97      0.97       232\n",
      "weighted avg       0.97      0.97      0.97       232\n",
      "\n",
      "[[57  0  0  1]\n",
      " [ 0 56  0  2]\n",
      " [ 0  0 57  1]\n",
      " [ 2  0  0 56]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(real_labels, predictions))\n",
    "print(confusion_matrix(real_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Drive_Health_App",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
