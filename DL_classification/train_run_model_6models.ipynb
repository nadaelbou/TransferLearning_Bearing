{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import splitfolders\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pipeline_torch_models import *\n",
    "from pipeline_torch_inception import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=yaml.load(open('config.yml', 'r'), Loader=yaml.FullLoader)\n",
    "seed = config['model_config']['initial_seed']\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False\n",
    "LVL_all = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1888 files [00:22, 82.43 files/s] \n"
     ]
    }
   ],
   "source": [
    "if LVL_all == True:\n",
    "    # define training and test data directories\n",
    "    data_dir  = r'C:\\Users\\FINAELB\\Documents\\Aalto\\Dayyan\\TL\\Data\\Scenario 05'\n",
    "    train_valid_dir = os.path.join(data_dir) \n",
    "    #test_dir  = os.path.join(data_dir, 'test')\n",
    "\n",
    "    splitfolders.ratio(input=train_valid_dir, output='split_data', ratio=(0.6, 0.4))\n",
    "    train_dir='split_data/train'\n",
    "    valid_dir='split_data/val'\n",
    "\n",
    "    splitfolders.ratio(input='split_data/val', output='Valid_Test', ratio=(0.5, 0.5))\n",
    "    valid_dir='Valid_Test/train'\n",
    "    test_dir='Valid_Test/val'\n",
    "\n",
    "    # Selecting mean and std values according to ImageNet dataset\n",
    "    mean = torch.tensor( [0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "else: \n",
    "    # define training and test data directories# define training and test data directories\n",
    "    data_dir  = r'C:\\Users\\FINAELB\\Documents\\Aalto\\Dayyan\\TL\\Data\\Scenario 10\\01 Training'\n",
    "    data_dir_test  = r'C:\\Users\\FINAELB\\Documents\\Aalto\\Dayyan\\TL\\Data\\Scenario 10\\02 Testing'\n",
    "    train_valid_dir = os.path.join(data_dir) \n",
    "    test_dir  = os.path.join(data_dir, 'test')\n",
    "\n",
    "    splitfolders.ratio(input=train_valid_dir, output='split_data', ratio=(0.6, 0.4))\n",
    "    train_dir='split_data/train'\n",
    "    valid_dir='split_data/val'\n",
    "\n",
    "    test_dir=r'C:\\Users\\FINAELB\\Documents\\Aalto\\Dayyan\\TL\\Data\\Scenario 10\\02 Testing'\n",
    "\n",
    "    # Selecting mean and std values according to ImageNet dataset\n",
    "    mean = torch.tensor( [0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and transform data using ImageFolder\n",
    "data_transforms = {\n",
    "    'train':  transforms.Compose([\n",
    "                                transforms.Resize([224,224]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean,std)\n",
    "                                ]),\n",
    "    'validation':  transforms.Compose([\n",
    "                                transforms.Resize([224,224]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean,std)\n",
    "                                ]),\n",
    "    'test':  transforms.Compose([\n",
    "                                transforms.Resize([224,224]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean,std)\n",
    "                                ])\n",
    "}\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=data_transforms[\"train\"])\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=data_transforms[\"validation\"])\n",
    "test_data  = datasets.ImageFolder(test_dir, transform=data_transforms[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and transform data using ImageFolder\n",
    "data_transforms_inception = {\n",
    "    'train_inception':  transforms.Compose([\n",
    "                                transforms.Resize([299,299]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean,std)\n",
    "                                ]),\n",
    "    'validation_inception':  transforms.Compose([\n",
    "                                transforms.Resize([299,299]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean,std)\n",
    "                                ]),\n",
    "    'test_inception':  transforms.Compose([\n",
    "                                transforms.Resize([299,299]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean,std)\n",
    "                                ])\n",
    "}\n",
    "\n",
    "train_data_inception = datasets.ImageFolder(train_dir, transform=data_transforms_inception[\"train_inception\"])\n",
    "valid_data_inception = datasets.ImageFolder(valid_dir, transform=data_transforms_inception[\"validation_inception\"])\n",
    "test_data_inception  = datasets.ImageFolder(test_dir, transform=data_transforms_inception[\"test_inception\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models and prepare for TL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FINAELB\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FINAELB\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "## MODEL 1: Resnet 18\n",
    "model_1 = models.resnet18(pretrained=True)\n",
    "layers=list(model_1._modules.keys())\n",
    "\n",
    "layers_frozen=layers[0:8]\n",
    "\n",
    "for layer in layers_frozen:\n",
    "    for param in model_1._modules[layer].parameters():\n",
    "        param.requires_grad=False\n",
    "        \n",
    "# modify last layer to match it our classes\n",
    "n_inputs = model_1.fc.in_features\n",
    "last_layer = nn.Linear(n_inputs, len(train_data.classes))\n",
    "model_1.fc = last_layer\n",
    "\n",
    "model_1 = models.resnet18(pretrained=True)\n",
    "layers=list(model_1._modules.keys())\n",
    "\n",
    "layers_frozen=layers[0:8]\n",
    "\n",
    "for layer in layers_frozen:\n",
    "    for param in model_1._modules[layer].parameters():\n",
    "        param.requires_grad=False\n",
    "        \n",
    "# modify last layer to match it our classes\n",
    "n_inputs = model_1.fc.in_features\n",
    "last_layer = nn.Linear(n_inputs, len(train_data.classes))\n",
    "model_1.fc = last_layer\n",
    "\n",
    "model_1 = model_1.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FINAELB\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "## MODEL 2: Resnet 50\n",
    "model_2 = models.resnet50(pretrained=True)\n",
    "layers=list(model_2._modules.keys())\n",
    "\n",
    "layers_frozen=layers[0:8]\n",
    "\n",
    "for layer in layers_frozen:\n",
    "    for param in model_2._modules[layer].parameters():\n",
    "        param.requires_grad=False\n",
    "        \n",
    "# modify last layer to match it our classes\n",
    "n_inputs = model_2.fc.in_features\n",
    "last_layer = nn.Linear(n_inputs, len(train_data.classes))\n",
    "model_2.fc = last_layer\n",
    "\n",
    "model_2 = model_2.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FINAELB\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "## MODEL 3: VGG 16\n",
    "\n",
    "model_3 = models.vgg16(pretrained=True)\n",
    "layers=list(model_3._modules.keys())\n",
    "\n",
    "layers_frozen=layers[0:30]\n",
    "\n",
    "for layer in layers_frozen:\n",
    "    for param in model_3._modules[layer].parameters():\n",
    "        param.requires_grad=False\n",
    "\n",
    "# modify last layer to match it our classes\n",
    "n_inputs = model_3.classifier[6].in_features\n",
    "last_layer = nn.Linear(n_inputs, len(train_data.classes))\n",
    "model_3.classifier[6] = last_layer\n",
    "\n",
    "model_3 = model_3.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FINAELB\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# MODEL 4: AlexNet\n",
    "\n",
    "model_4 = models.alexnet(pretrained=True)\n",
    "layers=list(model_4._modules.keys())\n",
    "\n",
    "layers_frozen=layers[0:12]\n",
    "\n",
    "for layer in layers_frozen:\n",
    "    for param in model_4._modules[layer].parameters():\n",
    "        param.requires_grad=False\n",
    "\n",
    "# modify last layer to match it our classes\n",
    "n_inputs = model_4.classifier[6].in_features\n",
    "last_layer = nn.Linear(n_inputs, len(train_data.classes))\n",
    "model_4.classifier[6] = last_layer\n",
    "\n",
    "model_4 = model_4.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FINAELB\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# MODEL 5: GoogleNet\n",
    "\n",
    "model_5 = models.googlenet(pretrained=True)\n",
    "layers=list(model_5._modules.keys())\n",
    "\n",
    "layers_frozen=layers[0:16]\n",
    "\n",
    "for layer in layers_frozen:\n",
    "    for param in model_5._modules[layer].parameters():\n",
    "        param.requires_grad=False\n",
    "\n",
    "# modify last layer to match it our classes\n",
    "\n",
    "n_inputs = model_5.fc.in_features\n",
    "last_layer = nn.Linear(n_inputs, len(train_data.classes))\n",
    "model_5.fc = last_layer\n",
    "\n",
    "model_5 = model_5.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FINAELB\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# MODEL 6: Inception\n",
    "model_6 = models.inception_v3(pretrained=True)\n",
    "layers=list(model_6._modules.keys())\n",
    "\n",
    "layers_frozen=layers[0:19]\n",
    "\n",
    "for layer in layers_frozen:\n",
    "    for param in model_6._modules[layer].parameters():\n",
    "        param.requires_grad\n",
    "\n",
    "# modify last layer to match it our classes\n",
    "n_inputs = model_6.fc.in_features\n",
    "last_layer = nn.Linear(n_inputs, len(train_data.classes))\n",
    "model_6.fc = last_layer\n",
    "\n",
    "model_6 = model_6.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_model_file(old_name, new_name, directory='models'):\n",
    "    # Construct full file paths\n",
    "    old_file_path = os.path.join(directory, old_name)\n",
    "    new_file_path = os.path.join(directory, new_name)\n",
    "    \n",
    "    # Check if the old file exists\n",
    "    if os.path.exists(old_file_path):\n",
    "        # Rename the file\n",
    "        os.rename(old_file_path, new_file_path)\n",
    "        print(f\"File renamed from {old_name} to {new_name}\")\n",
    "    else:\n",
    "        print(f\"File {old_name} does not exist in the directory {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 1 is : 0:00:21.654950 seconds.\n",
      "Epoch: 1 \tTraining Loss: 1.357278 \tValidation Loss: 1.230704\n",
      "Validation loss has descreased (inf-->1.230704). Saving model...\n",
      "Epoch [2/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 2 is : 0:00:11.522637 seconds.\n",
      "Epoch: 2 \tTraining Loss: 1.166948 \tValidation Loss: 1.059178\n",
      "Validation loss has descreased (1.230704-->1.059178). Saving model...\n",
      "Epoch [3/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 3 is : 0:00:11.487635 seconds.\n",
      "Epoch: 3 \tTraining Loss: 1.049008 \tValidation Loss: 0.999853\n",
      "Validation loss has descreased (1.059178-->0.999853). Saving model...\n",
      "Epoch [4/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 4 is : 0:00:11.272810 seconds.\n",
      "Epoch: 4 \tTraining Loss: 0.964990 \tValidation Loss: 0.971981\n",
      "Validation loss has descreased (0.999853-->0.971981). Saving model...\n",
      "Epoch [5/25], Learning Rate: 0.000350\n",
      "Duration of training at epoch 5 is : 0:00:13.381621 seconds.\n",
      "Epoch: 5 \tTraining Loss: 0.929363 \tValidation Loss: 0.876308\n",
      "Validation loss has descreased (0.971981-->0.876308). Saving model...\n",
      "Epoch [6/25], Learning Rate: 0.000210\n",
      "Duration of training at epoch 6 is : 0:00:12.993420 seconds.\n",
      "Epoch: 6 \tTraining Loss: 0.878458 \tValidation Loss: 0.877800\n",
      "seed has been changed. The new torch seed is 60\n",
      "Epoch [7/25], Learning Rate: 0.000098\n",
      "Duration of training at epoch 7 is : 0:00:12.462601 seconds.\n",
      "Epoch: 7 \tTraining Loss: 0.876852 \tValidation Loss: 0.846055\n",
      "Validation loss has descreased (0.876308-->0.846055). Saving model...\n",
      "Epoch [8/25], Learning Rate: 0.000026\n",
      "Duration of training at epoch 8 is : 0:00:12.633041 seconds.\n",
      "Epoch: 8 \tTraining Loss: 0.864593 \tValidation Loss: 0.838118\n",
      "Validation loss has descreased (0.846055-->0.838118). Saving model...\n",
      "Epoch [9/25], Learning Rate: 0.000000\n",
      "Duration of training at epoch 9 is : 0:00:12.155840 seconds.\n",
      "Epoch: 9 \tTraining Loss: 0.854056 \tValidation Loss: 0.837269\n",
      "Validation loss has descreased (0.838118-->0.837269). Saving model...\n",
      "Epoch [10/25], Learning Rate: 0.000977\n",
      "Duration of training at epoch 10 is : 0:00:11.669362 seconds.\n",
      "Epoch: 10 \tTraining Loss: 0.869149 \tValidation Loss: 0.836662\n",
      "Validation loss has descreased (0.837269-->0.836662). Saving model...\n",
      "Epoch [11/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 11 is : 0:00:12.212144 seconds.\n",
      "Epoch: 11 \tTraining Loss: 0.795691 \tValidation Loss: 0.735263\n",
      "Validation loss has descreased (0.836662-->0.735263). Saving model...\n",
      "Epoch [12/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 12 is : 0:00:11.908667 seconds.\n",
      "Epoch: 12 \tTraining Loss: 0.734385 \tValidation Loss: 0.710525\n",
      "Validation loss has descreased (0.735263-->0.710525). Saving model...\n",
      "Epoch [13/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 13 is : 0:00:11.870832 seconds.\n",
      "Epoch: 13 \tTraining Loss: 0.715827 \tValidation Loss: 0.669435\n",
      "Validation loss has descreased (0.710525-->0.669435). Saving model...\n",
      "Epoch [14/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 14 is : 0:00:12.511586 seconds.\n",
      "Epoch: 14 \tTraining Loss: 0.694473 \tValidation Loss: 0.653910\n",
      "Validation loss has descreased (0.669435-->0.653910). Saving model...\n",
      "Epoch [15/25], Learning Rate: 0.000350\n",
      "Duration of training at epoch 15 is : 0:00:11.998639 seconds.\n",
      "Epoch: 15 \tTraining Loss: 0.665490 \tValidation Loss: 0.650043\n",
      "Validation loss has descreased (0.653910-->0.650043). Saving model...\n",
      "Epoch [16/25], Learning Rate: 0.000210\n",
      "Duration of training at epoch 16 is : 0:00:12.186574 seconds.\n",
      "Epoch: 16 \tTraining Loss: 0.651243 \tValidation Loss: 0.637802\n",
      "Validation loss has descreased (0.650043-->0.637802). Saving model...\n",
      "Epoch [17/25], Learning Rate: 0.000098\n",
      "Duration of training at epoch 17 is : 0:00:11.472832 seconds.\n",
      "Epoch: 17 \tTraining Loss: 0.639780 \tValidation Loss: 0.622163\n",
      "Validation loss has descreased (0.637802-->0.622163). Saving model...\n",
      "Epoch [18/25], Learning Rate: 0.000026\n",
      "Duration of training at epoch 18 is : 0:00:11.525781 seconds.\n",
      "Epoch: 18 \tTraining Loss: 0.641403 \tValidation Loss: 0.621284\n",
      "Validation loss has descreased (0.622163-->0.621284). Saving model...\n",
      "Epoch [19/25], Learning Rate: 0.000000\n",
      "Duration of training at epoch 19 is : 0:00:11.500026 seconds.\n",
      "Epoch: 19 \tTraining Loss: 0.639344 \tValidation Loss: 0.623024\n",
      "seed has been changed. The new torch seed is 190\n",
      "Epoch [20/25], Learning Rate: 0.000977\n",
      "Duration of training at epoch 20 is : 0:00:11.184150 seconds.\n",
      "Epoch: 20 \tTraining Loss: 0.656924 \tValidation Loss: 0.599132\n",
      "Validation loss has descreased (0.621284-->0.599132). Saving model...\n",
      "Epoch [21/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 21 is : 0:00:11.329800 seconds.\n",
      "Epoch: 21 \tTraining Loss: 0.615261 \tValidation Loss: 0.584259\n",
      "Validation loss has descreased (0.599132-->0.584259). Saving model...\n",
      "Epoch [22/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 22 is : 0:00:11.140027 seconds.\n",
      "Epoch: 22 \tTraining Loss: 0.595581 \tValidation Loss: 0.564450\n",
      "Validation loss has descreased (0.584259-->0.564450). Saving model...\n",
      "Epoch [23/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 23 is : 0:00:11.129584 seconds.\n",
      "Epoch: 23 \tTraining Loss: 0.583770 \tValidation Loss: 0.560102\n",
      "Validation loss has descreased (0.564450-->0.560102). Saving model...\n",
      "Epoch [24/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 24 is : 0:00:11.132178 seconds.\n",
      "Epoch: 24 \tTraining Loss: 0.578181 \tValidation Loss: 0.547955\n",
      "Validation loss has descreased (0.560102-->0.547955). Saving model...\n",
      "Epoch [25/25], Learning Rate: 0.000350\n",
      "Duration of training at epoch 25 is : 0:00:11.304707 seconds.\n",
      "Epoch: 25 \tTraining Loss: 0.554744 \tValidation Loss: 0.529665\n",
      "Validation loss has descreased (0.547955-->0.529665). Saving model...\n",
      "File renamed from model_v11.pth to model1_v11.pth\n"
     ]
    }
   ],
   "source": [
    "pipeline1 = PipelineTorch(model_1, config)\n",
    "if skip_training == False:\n",
    "    pipeline1.train(train_data, valid_data, config['model_config']['version'])\n",
    "    # Example usage\n",
    "    old_file_name = 'model_' + config['model_config']['version'] + '.pth'\n",
    "    new_file_name = 'model1_' + config['model_config']['version'] + '.pth'\n",
    "    rename_model_file(old_file_name, new_file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 1 is : 0:00:11.602132 seconds.\n",
      "Epoch: 1 \tTraining Loss: 1.323315 \tValidation Loss: 1.222650\n",
      "Validation loss has descreased (inf-->1.222650). Saving model...\n",
      "Epoch [2/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 2 is : 0:00:11.656367 seconds.\n",
      "Epoch: 2 \tTraining Loss: 1.112048 \tValidation Loss: 1.100108\n",
      "Validation loss has descreased (1.222650-->1.100108). Saving model...\n",
      "Epoch [3/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 3 is : 0:00:11.792472 seconds.\n",
      "Epoch: 3 \tTraining Loss: 0.982494 \tValidation Loss: 0.905227\n",
      "Validation loss has descreased (1.100108-->0.905227). Saving model...\n",
      "Epoch [4/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 4 is : 0:00:12.307852 seconds.\n",
      "Epoch: 4 \tTraining Loss: 0.910128 \tValidation Loss: 0.855856\n",
      "Validation loss has descreased (0.905227-->0.855856). Saving model...\n",
      "Epoch [5/25], Learning Rate: 0.000350\n",
      "Duration of training at epoch 5 is : 0:00:12.240125 seconds.\n",
      "Epoch: 5 \tTraining Loss: 0.851026 \tValidation Loss: 0.820171\n",
      "Validation loss has descreased (0.855856-->0.820171). Saving model...\n",
      "Epoch [6/25], Learning Rate: 0.000210\n",
      "Duration of training at epoch 6 is : 0:00:12.273650 seconds.\n",
      "Epoch: 6 \tTraining Loss: 0.832321 \tValidation Loss: 0.808411\n",
      "Validation loss has descreased (0.820171-->0.808411). Saving model...\n",
      "Epoch [7/25], Learning Rate: 0.000098\n",
      "Duration of training at epoch 7 is : 0:00:13.155311 seconds.\n",
      "Epoch: 7 \tTraining Loss: 0.805766 \tValidation Loss: 0.803076\n",
      "Validation loss has descreased (0.808411-->0.803076). Saving model...\n",
      "Epoch [8/25], Learning Rate: 0.000026\n",
      "Duration of training at epoch 8 is : 0:00:11.024190 seconds.\n",
      "Epoch: 8 \tTraining Loss: 0.796044 \tValidation Loss: 0.793045\n",
      "Validation loss has descreased (0.803076-->0.793045). Saving model...\n",
      "Epoch [9/25], Learning Rate: 0.000000\n",
      "Duration of training at epoch 9 is : 0:00:12.885929 seconds.\n",
      "Epoch: 9 \tTraining Loss: 0.791468 \tValidation Loss: 0.790728\n",
      "Validation loss has descreased (0.793045-->0.790728). Saving model...\n",
      "Epoch [10/25], Learning Rate: 0.000977\n",
      "Duration of training at epoch 10 is : 0:00:14.460210 seconds.\n",
      "Epoch: 10 \tTraining Loss: 0.810038 \tValidation Loss: 0.815173\n",
      "seed has been changed. The new torch seed is 100\n",
      "Epoch [11/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 11 is : 0:00:12.859328 seconds.\n",
      "Epoch: 11 \tTraining Loss: 0.782651 \tValidation Loss: 0.784933\n",
      "Validation loss has descreased (0.790728-->0.784933). Saving model...\n",
      "Epoch [12/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 12 is : 0:00:12.456343 seconds.\n",
      "Epoch: 12 \tTraining Loss: 0.734616 \tValidation Loss: 0.730087\n",
      "Validation loss has descreased (0.784933-->0.730087). Saving model...\n",
      "Epoch [13/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 13 is : 0:00:11.945008 seconds.\n",
      "Epoch: 13 \tTraining Loss: 0.672146 \tValidation Loss: 0.680124\n",
      "Validation loss has descreased (0.730087-->0.680124). Saving model...\n",
      "Epoch [14/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 14 is : 0:00:12.239909 seconds.\n",
      "Epoch: 14 \tTraining Loss: 0.659172 \tValidation Loss: 0.637859\n",
      "Validation loss has descreased (0.680124-->0.637859). Saving model...\n",
      "Epoch [15/25], Learning Rate: 0.000350\n",
      "Duration of training at epoch 15 is : 0:00:12.939075 seconds.\n",
      "Epoch: 15 \tTraining Loss: 0.640613 \tValidation Loss: 0.637705\n",
      "Validation loss has descreased (0.637859-->0.637705). Saving model...\n",
      "Epoch [16/25], Learning Rate: 0.000210\n",
      "Duration of training at epoch 16 is : 0:00:12.973625 seconds.\n",
      "Epoch: 16 \tTraining Loss: 0.625366 \tValidation Loss: 0.630423\n",
      "Validation loss has descreased (0.637705-->0.630423). Saving model...\n",
      "Epoch [17/25], Learning Rate: 0.000098\n",
      "Duration of training at epoch 17 is : 0:00:12.749190 seconds.\n",
      "Epoch: 17 \tTraining Loss: 0.609176 \tValidation Loss: 0.618105\n",
      "Validation loss has descreased (0.630423-->0.618105). Saving model...\n",
      "Epoch [18/25], Learning Rate: 0.000026\n",
      "Duration of training at epoch 18 is : 0:00:12.684369 seconds.\n",
      "Epoch: 18 \tTraining Loss: 0.609672 \tValidation Loss: 0.615829\n",
      "Validation loss has descreased (0.618105-->0.615829). Saving model...\n",
      "Epoch [19/25], Learning Rate: 0.000000\n",
      "Duration of training at epoch 19 is : 0:00:13.272869 seconds.\n",
      "Epoch: 19 \tTraining Loss: 0.597394 \tValidation Loss: 0.616264\n",
      "seed has been changed. The new torch seed is 190\n",
      "Epoch [20/25], Learning Rate: 0.000977\n",
      "Duration of training at epoch 20 is : 0:00:14.783137 seconds.\n",
      "Epoch: 20 \tTraining Loss: 0.631051 \tValidation Loss: 0.614188\n",
      "Validation loss has descreased (0.615829-->0.614188). Saving model...\n",
      "Epoch [21/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 21 is : 0:00:14.143898 seconds.\n",
      "Epoch: 21 \tTraining Loss: 0.616496 \tValidation Loss: 0.638229\n",
      "seed has been changed. The new torch seed is 210\n",
      "Epoch [22/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 22 is : 0:00:13.898665 seconds.\n",
      "Epoch: 22 \tTraining Loss: 0.629327 \tValidation Loss: 0.585910\n",
      "Validation loss has descreased (0.614188-->0.585910). Saving model...\n",
      "Epoch [23/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 23 is : 0:00:12.324319 seconds.\n",
      "Epoch: 23 \tTraining Loss: 0.596778 \tValidation Loss: 0.574066\n",
      "Validation loss has descreased (0.585910-->0.574066). Saving model...\n",
      "Epoch [24/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 24 is : 0:00:11.681864 seconds.\n",
      "Epoch: 24 \tTraining Loss: 0.559617 \tValidation Loss: 0.552545\n",
      "Validation loss has descreased (0.574066-->0.552545). Saving model...\n",
      "Epoch [25/25], Learning Rate: 0.000350\n",
      "Duration of training at epoch 25 is : 0:00:12.023001 seconds.\n",
      "Epoch: 25 \tTraining Loss: 0.542098 \tValidation Loss: 0.551837\n",
      "Validation loss has descreased (0.552545-->0.551837). Saving model...\n",
      "File renamed from model_v11.pth to model2_v11.pth\n"
     ]
    }
   ],
   "source": [
    "pipeline2 = PipelineTorch(model_2, config)\n",
    "if skip_training == False: \n",
    "    pipeline2.train(train_data, valid_data, config['model_config']['version'])\n",
    "    # Example usage\n",
    "    old_file_name = 'model_' + config['model_config']['version'] + '.pth'\n",
    "    new_file_name = 'model2_' + config['model_config']['version'] + '.pth'\n",
    "    rename_model_file(old_file_name, new_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 1 is : 0:00:14.992119 seconds.\n",
      "Epoch: 1 \tTraining Loss: 1.429179 \tValidation Loss: 1.266027\n",
      "Validation loss has descreased (inf-->1.266027). Saving model...\n",
      "Epoch [2/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 2 is : 0:00:32.699790 seconds.\n",
      "Epoch: 2 \tTraining Loss: 1.336876 \tValidation Loss: 1.186913\n",
      "Validation loss has descreased (1.266027-->1.186913). Saving model...\n",
      "Epoch [3/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 3 is : 0:00:27.148982 seconds.\n",
      "Epoch: 3 \tTraining Loss: 1.220159 \tValidation Loss: 1.180158\n",
      "Validation loss has descreased (1.186913-->1.180158). Saving model...\n",
      "Epoch [4/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 4 is : 0:00:27.457396 seconds.\n",
      "Epoch: 4 \tTraining Loss: 1.251424 \tValidation Loss: 1.164181\n",
      "Validation loss has descreased (1.180158-->1.164181). Saving model...\n",
      "Epoch [5/25], Learning Rate: 0.000350\n",
      "Duration of training at epoch 5 is : 0:00:27.929885 seconds.\n",
      "Epoch: 5 \tTraining Loss: 1.194286 \tValidation Loss: 1.081703\n",
      "Validation loss has descreased (1.164181-->1.081703). Saving model...\n",
      "Epoch [6/25], Learning Rate: 0.000210\n",
      "Duration of training at epoch 6 is : 0:00:28.413853 seconds.\n",
      "Epoch: 6 \tTraining Loss: 1.183124 \tValidation Loss: 1.081137\n",
      "Validation loss has descreased (1.081703-->1.081137). Saving model...\n",
      "Epoch [7/25], Learning Rate: 0.000098\n",
      "Duration of training at epoch 7 is : 0:00:27.694318 seconds.\n",
      "Epoch: 7 \tTraining Loss: 1.175117 \tValidation Loss: 1.069569\n",
      "Validation loss has descreased (1.081137-->1.069569). Saving model...\n",
      "Epoch [8/25], Learning Rate: 0.000026\n",
      "Duration of training at epoch 8 is : 0:00:26.849223 seconds.\n",
      "Epoch: 8 \tTraining Loss: 1.153494 \tValidation Loss: 1.072700\n",
      "seed has been changed. The new torch seed is 80\n",
      "Epoch [9/25], Learning Rate: 0.000000\n",
      "Duration of training at epoch 9 is : 0:00:27.429705 seconds.\n",
      "Epoch: 9 \tTraining Loss: 1.140893 \tValidation Loss: 1.070497\n",
      "seed has been changed. The new torch seed is 90\n",
      "Epoch [10/25], Learning Rate: 0.000977\n",
      "Duration of training at epoch 10 is : 0:00:28.372370 seconds.\n",
      "Epoch: 10 \tTraining Loss: 1.162903 \tValidation Loss: 1.072471\n",
      "seed has been changed. The new torch seed is 100\n",
      "Epoch [11/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 11 is : 0:00:27.177737 seconds.\n",
      "Epoch: 11 \tTraining Loss: 1.186807 \tValidation Loss: 1.153274\n",
      "seed has been changed. The new torch seed is 110\n",
      "Epoch [12/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 12 is : 0:00:27.983706 seconds.\n",
      "Epoch: 12 \tTraining Loss: 1.180577 \tValidation Loss: 1.043661\n",
      "Validation loss has descreased (1.069569-->1.043661). Saving model...\n",
      "Epoch [13/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 13 is : 0:00:27.365066 seconds.\n",
      "Epoch: 13 \tTraining Loss: 1.164794 \tValidation Loss: 1.013260\n",
      "Validation loss has descreased (1.043661-->1.013260). Saving model...\n",
      "Epoch [14/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 14 is : 0:00:27.536668 seconds.\n",
      "Epoch: 14 \tTraining Loss: 1.153824 \tValidation Loss: 1.046756\n",
      "seed has been changed. The new torch seed is 140\n",
      "Epoch [15/25], Learning Rate: 0.000350\n",
      "Duration of training at epoch 15 is : 0:00:26.743640 seconds.\n",
      "Epoch: 15 \tTraining Loss: 1.161910 \tValidation Loss: 0.981733\n",
      "Validation loss has descreased (1.013260-->0.981733). Saving model...\n",
      "Epoch [16/25], Learning Rate: 0.000210\n",
      "Duration of training at epoch 16 is : 0:00:26.894024 seconds.\n",
      "Epoch: 16 \tTraining Loss: 1.133830 \tValidation Loss: 0.990283\n",
      "seed has been changed. The new torch seed is 160\n",
      "Epoch [17/25], Learning Rate: 0.000098\n",
      "Duration of training at epoch 17 is : 0:00:28.349406 seconds.\n",
      "Epoch: 17 \tTraining Loss: 1.100554 \tValidation Loss: 0.987182\n",
      "seed has been changed. The new torch seed is 170\n",
      "Epoch [18/25], Learning Rate: 0.000026\n",
      "Duration of training at epoch 18 is : 0:00:25.930280 seconds.\n",
      "Epoch: 18 \tTraining Loss: 1.121902 \tValidation Loss: 0.983935\n",
      "seed has been changed. The new torch seed is 180\n",
      "Epoch [19/25], Learning Rate: 0.000000\n",
      "Duration of training at epoch 19 is : 0:00:25.802618 seconds.\n",
      "Epoch: 19 \tTraining Loss: 1.075760 \tValidation Loss: 0.986118\n",
      "seed has been changed. The new torch seed is 190\n",
      "Epoch [20/25], Learning Rate: 0.000977\n",
      "Duration of training at epoch 20 is : 0:00:25.987935 seconds.\n",
      "Epoch: 20 \tTraining Loss: 1.200210 \tValidation Loss: 0.995149\n",
      "seed has been changed. The new torch seed is 200\n",
      "No improvement in training! Training stopped.\n",
      "Last improved epoch is #15\n",
      "File renamed from model_v11.pth to model3_v11.pth\n"
     ]
    }
   ],
   "source": [
    "pipeline3 = PipelineTorch(model_3, config)\n",
    "if skip_training == False: \n",
    "    pipeline3.train(train_data, valid_data, config['model_config']['version'])\n",
    "    old_file_name = 'model_' + config['model_config']['version'] + '.pth'\n",
    "    new_file_name = 'model3_' + config['model_config']['version'] + '.pth'\n",
    "    rename_model_file(old_file_name, new_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 1 is : 0:00:15.165866 seconds.\n",
      "Epoch: 1 \tTraining Loss: 1.517926 \tValidation Loss: 1.414316\n",
      "Validation loss has descreased (inf-->1.414316). Saving model...\n",
      "Epoch [2/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 2 is : 0:00:14.632850 seconds.\n",
      "Epoch: 2 \tTraining Loss: 1.449749 \tValidation Loss: 1.457431\n",
      "seed has been changed. The new torch seed is 20\n",
      "Epoch [3/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 3 is : 0:00:15.201380 seconds.\n",
      "Epoch: 3 \tTraining Loss: 1.429688 \tValidation Loss: 1.334543\n",
      "Validation loss has descreased (1.414316-->1.334543). Saving model...\n",
      "Epoch [4/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 4 is : 0:00:13.900713 seconds.\n",
      "Epoch: 4 \tTraining Loss: 1.462822 \tValidation Loss: 1.390813\n",
      "seed has been changed. The new torch seed is 40\n",
      "Epoch [5/25], Learning Rate: 0.000350\n",
      "Duration of training at epoch 5 is : 0:00:15.456530 seconds.\n",
      "Epoch: 5 \tTraining Loss: 1.414714 \tValidation Loss: 1.327162\n",
      "Validation loss has descreased (1.334543-->1.327162). Saving model...\n",
      "Epoch [6/25], Learning Rate: 0.000210\n",
      "Duration of training at epoch 6 is : 0:00:14.199987 seconds.\n",
      "Epoch: 6 \tTraining Loss: 1.389001 \tValidation Loss: 1.336043\n",
      "seed has been changed. The new torch seed is 60\n",
      "Epoch [7/25], Learning Rate: 0.000098\n",
      "Duration of training at epoch 7 is : 0:00:14.888666 seconds.\n",
      "Epoch: 7 \tTraining Loss: 1.364583 \tValidation Loss: 1.312813\n",
      "Validation loss has descreased (1.327162-->1.312813). Saving model...\n",
      "Epoch [8/25], Learning Rate: 0.000026\n",
      "Duration of training at epoch 8 is : 0:00:14.283099 seconds.\n",
      "Epoch: 8 \tTraining Loss: 1.371330 \tValidation Loss: 1.326089\n",
      "seed has been changed. The new torch seed is 80\n",
      "Epoch [9/25], Learning Rate: 0.000000\n",
      "Duration of training at epoch 9 is : 0:00:15.485770 seconds.\n",
      "Epoch: 9 \tTraining Loss: 1.372157 \tValidation Loss: 1.321754\n",
      "seed has been changed. The new torch seed is 90\n",
      "Epoch [10/25], Learning Rate: 0.000977\n",
      "Duration of training at epoch 10 is : 0:00:15.748445 seconds.\n",
      "Epoch: 10 \tTraining Loss: 1.392249 \tValidation Loss: 1.339390\n",
      "seed has been changed. The new torch seed is 100\n",
      "Epoch [11/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 11 is : 0:00:15.447813 seconds.\n",
      "Epoch: 11 \tTraining Loss: 1.453613 \tValidation Loss: 1.496854\n",
      "seed has been changed. The new torch seed is 110\n",
      "Epoch [12/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 12 is : 0:00:15.268618 seconds.\n",
      "Epoch: 12 \tTraining Loss: 1.436772 \tValidation Loss: 1.386570\n",
      "seed has been changed. The new torch seed is 120\n",
      "No improvement in training! Training stopped.\n",
      "Last improved epoch is #7\n",
      "File renamed from model_v11.pth to model4_v11.pth\n"
     ]
    }
   ],
   "source": [
    "pipeline4 = PipelineTorch(model_4, config)\n",
    "if skip_training == False: \n",
    "    pipeline4.train(train_data, valid_data, config['model_config']['version'])\n",
    "    old_file_name = 'model_' + config['model_config']['version'] + '.pth'\n",
    "    new_file_name = 'model4_' + config['model_config']['version'] + '.pth'\n",
    "    rename_model_file(old_file_name, new_file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 1 is : 0:00:16.112891 seconds.\n",
      "Epoch: 1 \tTraining Loss: 1.362739 \tValidation Loss: 1.289792\n",
      "Validation loss has descreased (inf-->1.289792). Saving model...\n",
      "Epoch [2/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 2 is : 0:00:15.580293 seconds.\n",
      "Epoch: 2 \tTraining Loss: 1.215248 \tValidation Loss: 1.157542\n",
      "Validation loss has descreased (1.289792-->1.157542). Saving model...\n",
      "Epoch [3/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 3 is : 0:00:16.214869 seconds.\n",
      "Epoch: 3 \tTraining Loss: 1.143358 \tValidation Loss: 1.114215\n",
      "Validation loss has descreased (1.157542-->1.114215). Saving model...\n",
      "Epoch [4/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 4 is : 0:00:15.916175 seconds.\n",
      "Epoch: 4 \tTraining Loss: 1.090414 \tValidation Loss: 1.052225\n",
      "Validation loss has descreased (1.114215-->1.052225). Saving model...\n",
      "Epoch [5/25], Learning Rate: 0.000350\n",
      "Duration of training at epoch 5 is : 0:00:15.856569 seconds.\n",
      "Epoch: 5 \tTraining Loss: 1.046689 \tValidation Loss: 1.033466\n",
      "Validation loss has descreased (1.052225-->1.033466). Saving model...\n",
      "Epoch [6/25], Learning Rate: 0.000210\n",
      "Duration of training at epoch 6 is : 0:00:15.768386 seconds.\n",
      "Epoch: 6 \tTraining Loss: 1.034400 \tValidation Loss: 1.013247\n",
      "Validation loss has descreased (1.033466-->1.013247). Saving model...\n",
      "Epoch [7/25], Learning Rate: 0.000098\n",
      "Duration of training at epoch 7 is : 0:00:15.119871 seconds.\n",
      "Epoch: 7 \tTraining Loss: 1.002259 \tValidation Loss: 0.998809\n",
      "Validation loss has descreased (1.013247-->0.998809). Saving model...\n",
      "Epoch [8/25], Learning Rate: 0.000026\n",
      "Duration of training at epoch 8 is : 0:00:15.111857 seconds.\n",
      "Epoch: 8 \tTraining Loss: 1.006143 \tValidation Loss: 0.999821\n",
      "seed has been changed. The new torch seed is 80\n",
      "Epoch [9/25], Learning Rate: 0.000000\n",
      "Duration of training at epoch 9 is : 0:00:15.469899 seconds.\n",
      "Epoch: 9 \tTraining Loss: 0.990752 \tValidation Loss: 0.995080\n",
      "Validation loss has descreased (0.998809-->0.995080). Saving model...\n",
      "Epoch [10/25], Learning Rate: 0.000977\n",
      "Duration of training at epoch 10 is : 0:00:16.072713 seconds.\n",
      "Epoch: 10 \tTraining Loss: 0.993878 \tValidation Loss: 0.959204\n",
      "Validation loss has descreased (0.995080-->0.959204). Saving model...\n",
      "Epoch [11/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 11 is : 0:00:16.061013 seconds.\n",
      "Epoch: 11 \tTraining Loss: 0.950014 \tValidation Loss: 0.929396\n",
      "Validation loss has descreased (0.959204-->0.929396). Saving model...\n",
      "Epoch [12/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 12 is : 0:00:16.333984 seconds.\n",
      "Epoch: 12 \tTraining Loss: 0.923331 \tValidation Loss: 0.897990\n",
      "Validation loss has descreased (0.929396-->0.897990). Saving model...\n",
      "Epoch [13/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 13 is : 0:00:16.153454 seconds.\n",
      "Epoch: 13 \tTraining Loss: 0.897459 \tValidation Loss: 0.863797\n",
      "Validation loss has descreased (0.897990-->0.863797). Saving model...\n",
      "Epoch [14/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 14 is : 0:00:15.688325 seconds.\n",
      "Epoch: 14 \tTraining Loss: 0.868868 \tValidation Loss: 0.873448\n",
      "seed has been changed. The new torch seed is 140\n",
      "Epoch [15/25], Learning Rate: 0.000350\n",
      "Duration of training at epoch 15 is : 0:00:16.111649 seconds.\n",
      "Epoch: 15 \tTraining Loss: 0.859744 \tValidation Loss: 0.829258\n",
      "Validation loss has descreased (0.863797-->0.829258). Saving model...\n",
      "Epoch [16/25], Learning Rate: 0.000210\n",
      "Duration of training at epoch 16 is : 0:00:16.631993 seconds.\n",
      "Epoch: 16 \tTraining Loss: 0.825519 \tValidation Loss: 0.826713\n",
      "Validation loss has descreased (0.829258-->0.826713). Saving model...\n",
      "Epoch [17/25], Learning Rate: 0.000098\n",
      "Duration of training at epoch 17 is : 0:00:17.197800 seconds.\n",
      "Epoch: 17 \tTraining Loss: 0.826559 \tValidation Loss: 0.823496\n",
      "Validation loss has descreased (0.826713-->0.823496). Saving model...\n",
      "Epoch [18/25], Learning Rate: 0.000026\n",
      "Duration of training at epoch 18 is : 0:00:17.651750 seconds.\n",
      "Epoch: 18 \tTraining Loss: 0.818950 \tValidation Loss: 0.817601\n",
      "Validation loss has descreased (0.823496-->0.817601). Saving model...\n",
      "Epoch [19/25], Learning Rate: 0.000000\n",
      "Duration of training at epoch 19 is : 0:00:17.043144 seconds.\n",
      "Epoch: 19 \tTraining Loss: 0.813379 \tValidation Loss: 0.816508\n",
      "Validation loss has descreased (0.817601-->0.816508). Saving model...\n",
      "Epoch [20/25], Learning Rate: 0.000977\n",
      "Duration of training at epoch 20 is : 0:00:17.490957 seconds.\n",
      "Epoch: 20 \tTraining Loss: 0.824529 \tValidation Loss: 0.835595\n",
      "seed has been changed. The new torch seed is 200\n",
      "Epoch [21/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 21 is : 0:00:16.843016 seconds.\n",
      "Epoch: 21 \tTraining Loss: 0.812615 \tValidation Loss: 0.780573\n",
      "Validation loss has descreased (0.816508-->0.780573). Saving model...\n",
      "Epoch [22/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 22 is : 0:00:16.166611 seconds.\n",
      "Epoch: 22 \tTraining Loss: 0.776913 \tValidation Loss: 0.771508\n",
      "Validation loss has descreased (0.780573-->0.771508). Saving model...\n",
      "Epoch [23/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 23 is : 0:00:16.500153 seconds.\n",
      "Epoch: 23 \tTraining Loss: 0.784552 \tValidation Loss: 0.763136\n",
      "Validation loss has descreased (0.771508-->0.763136). Saving model...\n",
      "Epoch [24/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 24 is : 0:00:16.092664 seconds.\n",
      "Epoch: 24 \tTraining Loss: 0.739612 \tValidation Loss: 0.747688\n",
      "Validation loss has descreased (0.763136-->0.747688). Saving model...\n",
      "Epoch [25/25], Learning Rate: 0.000350\n",
      "Duration of training at epoch 25 is : 0:00:16.205531 seconds.\n",
      "Epoch: 25 \tTraining Loss: 0.746552 \tValidation Loss: 0.733525\n",
      "Validation loss has descreased (0.747688-->0.733525). Saving model...\n",
      "File renamed from model_v11.pth to model5_v11.pth\n"
     ]
    }
   ],
   "source": [
    "pipeline5 = PipelineTorch(model_5, config)\n",
    "if skip_training == False: \n",
    "    pipeline5.train(train_data, valid_data, config['model_config']['version'])\n",
    "    old_file_name = 'model_' + config['model_config']['version'] + '.pth'\n",
    "    new_file_name = 'model5_' + config['model_config']['version'] + '.pth'\n",
    "    rename_model_file(old_file_name, new_file_name)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 1 is : 0:02:52.788070 seconds.\n",
      "Epoch: 1 \tTraining Loss: 0.666084 \tValidation Loss: 2.804018\n",
      "Validation loss has descreased (inf-->2.804018). Saving model...\n",
      "Epoch [2/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 2 is : 0:02:32.468964 seconds.\n",
      "Epoch: 2 \tTraining Loss: 0.379814 \tValidation Loss: 0.610710\n",
      "Validation loss has descreased (2.804018-->0.610710). Saving model...\n",
      "Epoch [3/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 3 is : 0:02:20.821934 seconds.\n",
      "Epoch: 3 \tTraining Loss: 0.195391 \tValidation Loss: 2.710434\n",
      "seed has been changed. The new torch seed is 30\n",
      "Epoch [4/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 4 is : 0:02:19.389639 seconds.\n",
      "Epoch: 4 \tTraining Loss: 0.056632 \tValidation Loss: 0.336693\n",
      "Validation loss has descreased (0.610710-->0.336693). Saving model...\n",
      "Epoch [5/25], Learning Rate: 0.000350\n",
      "Duration of training at epoch 5 is : 0:02:30.807771 seconds.\n",
      "Epoch: 5 \tTraining Loss: 0.068850 \tValidation Loss: 1.307450\n",
      "seed has been changed. The new torch seed is 50\n",
      "Epoch [6/25], Learning Rate: 0.000210\n",
      "Duration of training at epoch 6 is : 0:02:29.989566 seconds.\n",
      "Epoch: 6 \tTraining Loss: 0.035918 \tValidation Loss: 0.020904\n",
      "Validation loss has descreased (0.336693-->0.020904). Saving model...\n",
      "Epoch [7/25], Learning Rate: 0.000098\n",
      "Duration of training at epoch 7 is : 0:02:14.331080 seconds.\n",
      "Epoch: 7 \tTraining Loss: 0.015515 \tValidation Loss: 0.034919\n",
      "seed has been changed. The new torch seed is 70\n",
      "Epoch [8/25], Learning Rate: 0.000026\n",
      "Duration of training at epoch 8 is : 0:02:14.327152 seconds.\n",
      "Epoch: 8 \tTraining Loss: 0.014711 \tValidation Loss: 0.007583\n",
      "Validation loss has descreased (0.020904-->0.007583). Saving model...\n",
      "Epoch [9/25], Learning Rate: 0.000000\n",
      "Duration of training at epoch 9 is : 0:02:17.051756 seconds.\n",
      "Epoch: 9 \tTraining Loss: 0.006409 \tValidation Loss: 0.004141\n",
      "Validation loss has descreased (0.007583-->0.004141). Saving model...\n",
      "Epoch [10/25], Learning Rate: 0.000977\n",
      "Duration of training at epoch 10 is : 0:02:26.464258 seconds.\n",
      "Epoch: 10 \tTraining Loss: 0.060215 \tValidation Loss: 2.028367\n",
      "seed has been changed. The new torch seed is 100\n",
      "Epoch [11/25], Learning Rate: 0.000907\n",
      "Duration of training at epoch 11 is : 0:02:26.178355 seconds.\n",
      "Epoch: 11 \tTraining Loss: 0.213354 \tValidation Loss: 16.002356\n",
      "seed has been changed. The new torch seed is 110\n",
      "Epoch [12/25], Learning Rate: 0.000797\n",
      "Duration of training at epoch 12 is : 0:02:28.061802 seconds.\n",
      "Epoch: 12 \tTraining Loss: 0.145521 \tValidation Loss: 25.307335\n",
      "seed has been changed. The new torch seed is 120\n",
      "Epoch [13/25], Learning Rate: 0.000659\n",
      "Duration of training at epoch 13 is : 0:02:27.232044 seconds.\n",
      "Epoch: 13 \tTraining Loss: 0.082655 \tValidation Loss: 0.580260\n",
      "seed has been changed. The new torch seed is 130\n",
      "Epoch [14/25], Learning Rate: 0.000504\n",
      "Duration of training at epoch 14 is : 0:02:27.243995 seconds.\n",
      "Epoch: 14 \tTraining Loss: 0.087559 \tValidation Loss: 4.075273\n",
      "seed has been changed. The new torch seed is 140\n",
      "No improvement in training! Training stopped.\n",
      "Last improved epoch is #9\n",
      "File renamed from model_v11.pth to model6_v11.pth\n"
     ]
    }
   ],
   "source": [
    "pipeline6 = PipelineTorchInception(model_6, config)\n",
    "if skip_training == False:\n",
    "    pipeline6.train(train_data_inception, valid_data_inception, config['model_config']['version'])\n",
    "    old_file_name = 'model_' + config['model_config']['version'] + '.pth'\n",
    "    new_file_name = 'model6_' + config['model_config']['version'] + '.pth'\n",
    "    rename_model_file(old_file_name, new_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post_Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'models\\model1_v11.pth'\n",
      "=> loaded checkpoint 'models\\model1_v11.pth' (epoch 25)\n",
      "=> loading checkpoint 'models\\model2_v11.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FINAELB\\Documents\\Aalto\\Dayyan\\TL\\TL_CWT\\DL_classification\\pipeline_torch_models.py:151: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint=torch.load(os.path.join(self.artifact_path, f\"model{nb_model}_{version}.pth\"),map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint 'models\\model2_v11.pth' (epoch 25)\n",
      "=> loading checkpoint 'models\\model3_v11.pth'\n",
      "=> loaded checkpoint 'models\\model3_v11.pth' (epoch 15)\n",
      "=> loading checkpoint 'models\\model4_v11.pth'\n",
      "=> loaded checkpoint 'models\\model4_v11.pth' (epoch 7)\n",
      "=> loading checkpoint 'models\\model5_v11.pth'\n",
      "=> loaded checkpoint 'models\\model5_v11.pth' (epoch 25)\n",
      "=> loading checkpoint 'models\\model6_v11.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FINAELB\\Documents\\Aalto\\Dayyan\\TL\\TL_CWT\\DL_classification\\pipeline_torch_inception.py:149: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint=torch.load(os.path.join(self.artifact_path, f\"model{nb_model}_{version}.pth\"),map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint 'models\\model6_v11.pth' (epoch 9)\n"
     ]
    }
   ],
   "source": [
    "pipeline1.load_checkpoint(config['model_config']['version'],nb_model=1)\n",
    "pipeline2.load_checkpoint(config['model_config']['version'],nb_model=2)\n",
    "pipeline3.load_checkpoint(config['model_config']['version'],nb_model=3)\n",
    "pipeline4.load_checkpoint(config['model_config']['version'],nb_model=4)\n",
    "pipeline5.load_checkpoint(config['model_config']['version'],nb_model=5)\n",
    "pipeline6.load_checkpoint(config['model_config']['version'],nb_model=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses1_test, average_loss1_test, predictions1_test, real_labels1_test, acc1_test= pipeline1.predict(test_data)   \n",
    "losses2_test, average_loss2_test, predictions2_test, real_labels2_test, acc2_test= pipeline2.predict(test_data)   \n",
    "losses3_test, average_loss3_test, predictions3_test, real_labels3_test, acc3_test= pipeline3.predict(test_data)   \n",
    "losses4_test, average_loss4_test, predictions4_test, real_labels4_test, acc4_test= pipeline4.predict(test_data)   \n",
    "losses5_test, average_loss5_test, predictions5_test, real_labels5_test, acc5_test= pipeline5.predict(test_data)\n",
    "losses6_test, average_loss6_test, predictions6_test, real_labels6_test, acc6_test= pipeline6.predict(test_data_inception)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses1_valid, average_loss1_valid, predictions1_valid, real_labels1_valid, acc1_valid= pipeline1.predict(valid_data)   \n",
    "losses2_valid, average_loss2_valid, predictions2_valid, real_labels2_valid, acc2_valid= pipeline2.predict(valid_data)   \n",
    "losses3_valid, average_loss3_valid, predictions3_valid, real_labels3_valid, acc3_valid= pipeline3.predict(valid_data)   \n",
    "losses4_valid, average_loss4_valid, predictions4_valid, real_labels4_valid, acc4_valid= pipeline4.predict(valid_data)   \n",
    "losses5_valid, average_loss5_valid, predictions5_valid, real_labels5_valid, acc5_valid= pipeline5.predict(valid_data)  \n",
    "losses6_valid, average_loss6_valid, predictions6_valid, real_labels6_valid, acc6_valid= pipeline6.predict(valid_data_inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "losses1_train, average_loss1_train, predictions1_train, real_labels1_train, acc1_train= pipeline1.predict(train_data)   \n",
    "losses2_train, average_loss2_train, predictions2_train, real_labels2_train, acc2_train= pipeline2.predict(train_data)   \n",
    "losses3_train, average_loss3_train, predictions3_train, real_labels3_train, acc3_train= pipeline3.predict(train_data)   \n",
    "losses4_train, average_loss4_train, predictions4_train, real_labels4_train, acc4_train= pipeline4.predict(train_data)   \n",
    "losses5_train, average_loss5_train, predictions5_train, real_labels5_train, acc5_train= pipeline5.predict(train_data) \n",
    "losses6_train, average_loss6_train, predictions6_train, real_labels6_train, acc6_train= pipeline6.predict(train_data_inception) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from the pipeline predictions (replace these with your actual outputs)\n",
    "train_accuracies = [acc1_train[0], acc2_train[0], acc3_train[0], acc4_train[0], acc5_train[0], acc6_train[0]]\n",
    "valid_accuracies = [acc1_valid[0], acc2_valid[0], acc3_valid[0], acc4_valid[0], acc5_valid[0], acc6_valid[0]]\n",
    "test_accuracies = [acc1_test[0], acc2_test[0], acc3_test[0], acc4_test[0], acc5_test[0], acc6_test[0]]\n",
    "\n",
    "train_losses = [average_loss1_train, average_loss2_train, average_loss3_train, average_loss4_train, average_loss5_train, average_loss6_train]\n",
    "valid_losses = [average_loss1_valid, average_loss2_valid, average_loss3_valid, average_loss4_valid, average_loss5_valid, average_loss6_valid]\n",
    "test_losses = [average_loss1_test, average_loss2_test, average_loss3_test, average_loss4_test, average_loss5_test, average_loss6_test]\n",
    "\n",
    "# Creating a DataFrame with the organized data\n",
    "df = pd.DataFrame({\n",
    "    'Model': ['Model 1', 'Model 2', 'Model 3', 'Model 4', 'Model 5', 'Model 6'],\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Validation Accuracy': valid_accuracies,\n",
    "    'Test Accuracy': test_accuracies,\n",
    "    'Train Loss': train_losses,\n",
    "    'Validation Loss': valid_losses,\n",
    "    'Test Loss': test_losses\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>85.381356</td>\n",
       "      <td>85.830619</td>\n",
       "      <td>88.559322</td>\n",
       "      <td>0.522318</td>\n",
       "      <td>0.529665</td>\n",
       "      <td>0.464089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>84.576271</td>\n",
       "      <td>82.980456</td>\n",
       "      <td>85.381356</td>\n",
       "      <td>0.503816</td>\n",
       "      <td>0.551837</td>\n",
       "      <td>0.489256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>65.042373</td>\n",
       "      <td>67.345277</td>\n",
       "      <td>71.822034</td>\n",
       "      <td>0.993737</td>\n",
       "      <td>0.981733</td>\n",
       "      <td>0.948867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>50.593220</td>\n",
       "      <td>49.185668</td>\n",
       "      <td>43.432203</td>\n",
       "      <td>1.313484</td>\n",
       "      <td>1.312813</td>\n",
       "      <td>1.327955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model 5</td>\n",
       "      <td>77.457627</td>\n",
       "      <td>75.407166</td>\n",
       "      <td>74.364407</td>\n",
       "      <td>0.684670</td>\n",
       "      <td>0.733525</td>\n",
       "      <td>0.730239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Model 6</td>\n",
       "      <td>99.915254</td>\n",
       "      <td>99.837134</td>\n",
       "      <td>99.576271</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.021215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Train Accuracy  Validation Accuracy  Test Accuracy  Train Loss  \\\n",
       "0  Model 1       85.381356            85.830619      88.559322    0.522318   \n",
       "1  Model 2       84.576271            82.980456      85.381356    0.503816   \n",
       "2  Model 3       65.042373            67.345277      71.822034    0.993737   \n",
       "3  Model 4       50.593220            49.185668      43.432203    1.313484   \n",
       "4  Model 5       77.457627            75.407166      74.364407    0.684670   \n",
       "5  Model 6       99.915254            99.837134      99.576271    0.000957   \n",
       "\n",
       "   Validation Loss  Test Loss  \n",
       "0         0.529665   0.464089  \n",
       "1         0.551837   0.489256  \n",
       "2         0.981733   0.948867  \n",
       "3         1.312813   1.327955  \n",
       "4         0.733525   0.730239  \n",
       "5         0.004141   0.021215  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Drive_Health_App",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
